{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Input\n",
    "\n",
    "To do any computation, you need to have data. Getting the data in the framework of a workflow is therefore the first step of every analysis. Nipype provides many different modules to grab or select the data:\n",
    "\n",
    "    DataFinder\n",
    "    DataGrabber\n",
    "    FreeSurferSource\n",
    "    JSONFileGrabber\n",
    "    S3DataGrabber\n",
    "    SSHDataGrabber\n",
    "    SelectFiles\n",
    "    XNATSource\n",
    "\n",
    "This tutorial will only cover some of them. For the rest, see the section [``interfaces.io``](http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html) on the official homepage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset structure\n",
    "\n",
    "To be able to import data, you first need to be aware about the structure of your dataset. The structure of the dataset for this tutorial is according to BIDS, and looks as follows:\n",
    "\n",
    "\tTODO\n",
    "    ds102\n",
    "    ├── CHANGES\n",
    "    ├── dataset_description.json\n",
    "    ├── participants.tsv\n",
    "    ├── README\n",
    "    ├── sub-01\n",
    "    │   ├── anat\n",
    "    │   │   └── sub-01_T1w.nii.gz\n",
    "    │   └── func\n",
    "    │       ├── sub-01_task-flanker_run-1_bold.nii.gz\n",
    "    │       ├── sub-01_task-flanker_run-1_events.tsv\n",
    "    │       ├── sub-01_task-flanker_run-2_bold.nii.gz\n",
    "    │       └── sub-01_task-flanker_run-2_events.tsv\n",
    "    ├── sub-02\n",
    "    │   ├── anat\n",
    "    │   │   └── sub-02_T1w.nii.gz\n",
    "    │   └── func\n",
    "    │       ├── sub-02_task-flanker_run-1_bold.nii.gz\n",
    "    │       ├── sub-02_task-flanker_run-1_events.tsv\n",
    "    │       ├── sub-02_task-flanker_run-2_bold.nii.gz\n",
    "    │       └── sub-02_task-flanker_run-2_events.tsv\n",
    "    ├── sub-03\n",
    "    │   ├── anat\n",
    "    │   │   └── sub-03_T1w.nii.gz\n",
    "    │   └── func\n",
    "    │       ├── sub-03_task-flanker_run-1_bold.nii.gz\n",
    "    │       ├── sub-03_task-flanker_run-1_events.tsv\n",
    "    │       ├── sub-03_task-flanker_run-2_bold.nii.gz\n",
    "    │       └── sub-03_task-flanker_run-2_events.tsv\n",
    "    ├── ...\n",
    "    .\n",
    "    └── task-flanker_bold.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DataGrabber\n",
    "\n",
    "``DataGrabber`` is a generic data grabber module that wraps around ``glob`` to select your neuroimaging data in an intelligent way. As an example, let's assume we want to grab the anatomical and functional images of a certain subject.\n",
    "\n",
    "First, we need to create the ``DataGrabber`` node. This node needs to have some input fields for all dynamic parameters (e.g. subject identifier, task identifier), as well as the two desired output fields ``anat`` and ``func``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import DataGrabber, Node\n",
    "\n",
    "# Create DataGrabber node\n",
    "dg = Node(DataGrabber(infields=['subject_id', 'task_name'],\n",
    "                      outfields=['anat', 'func']),\n",
    "          name='datagrabber')\n",
    "\n",
    "# Location of the dataset folder\n",
    "dg.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "# Necessary default parameters\n",
    "dg.inputs.template = '*'\n",
    "dg.inputs.sort_filelist = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Second, we know that the two files we desire are the the following location:\n",
    "\n",
    "    anat = /data/ds000114/sub-01/anat/sub-01_T1w.nii.gz\n",
    "    func = /data/ds000114/sub-01/func/sub-01_task-fingerfootlips_bold.nii.gz\n",
    "\n",
    "We see that the two files only have two dynamic parameters between subjects and task names:\n",
    "\n",
    "    subject_id: in this case 'sub-01'\n",
    "    task_name: in this case fingerfootlips\n",
    "\n",
    "This means that we can rewrite the paths as follows:\n",
    "\n",
    "    anat = /data/ds102/[subject_id]/anat/[subject_id]_T1w.nii.gz\n",
    "    func = /data/ds102/[subject_id]/func/[subject_id]_task-[task_name]_bold.nii.gz\n",
    "\n",
    "Therefore, we need the parameter ``subject_id`` for the anatomical image and the parameter ``subject_id`` and ``task_name`` for the functional image. In the context of DataGabber, this is specified as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dg.inputs.template_args = {'anat': [['subject_id']],\n",
    "                           'func': [['subject_id', 'task_name']]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, comes the most important part of DataGrabber. We need to specify the template structure to find the specific data. This can be done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dg.inputs.field_template = {'anat': 'sub-%02d/anat/*_T1w.nii.gz',\n",
    "                            'func': 'sub-%02d/func/*task-%s_bold.nii.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TODO\n",
    "You'll notice that we use ``%s``, ``%02d`` and ``*`` for placeholders in the data paths. ``%s`` is a placeholder for a string and is filled out by ``subject_id``. ``%02d`` is a placeholder for a integer number and is filled out by ``task_id``. ``*`` is used as a wild card, e.g. a placeholder for any possible string combination. This is all to set up the ``DataGrabber`` node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TODO Now it is up to you how you want to feed the dynamic parameters into the node. You can either do this by using another node (e.g. ``IdentityInterface``) and feed ``subject_id`` and ``task_id`` as connections to the ``DataGrabber`` node or specify them directly as node inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using the IdentityInterface\n",
    "from nipype import IdentityInterface\n",
    "infosource = Node(IdentityInterface(fields=['subject_id', 'task_name']),\n",
    "                  name=\"infosource\")\n",
    "infosource.inputs.task_name = \"fingerfootlips\"\n",
    "subject_id_list = [1, 2]\n",
    "infosource.iterables = [('subject_id', subject_id_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you only have to connect ``infosource`` with your ``DataGrabber`` and run the workflow to iterate over subjects 1, 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you specify the inputs to the ``DataGrabber`` node directly, you can do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Specifying the input fields of DataGrabber directly\n",
    "dg.inputs.subject_id = 1\n",
    "dg.inputs.task_name = \"fingerfootlips\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's run the ``DataGrabber`` node and let's look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170716-02:05:13,598 workflow INFO:\n",
      "\t Executing node datagrabber in dir: /tmp/tmpphaq17mj/datagrabber\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "anat = /data/ds000114/sub-01/anat/sub-01_T1w.nii.gz\n",
       "func = /data/ds000114/sub-01/func/sub-01_task-fingerfootlips_bold.nii.gz"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SelectFiles\n",
    "\n",
    "`SelectFiles` is a more flexible alternative to `DataGrabber`. It uses the {}-based string formating syntax to plug values into string templates and collect the data. These templates can also be combined with glob wild cards. The field names in the formatting template (i.e. the terms in braces) will become inputs fields on the interface, and the keys in the templates dictionary will form the output fields.\n",
    "\n",
    "Let's focus again on the data we want to import:\n",
    "\n",
    "    anat = /data/ds000114/sub-01/anat/sub-01_T1w.nii.gz\n",
    "    func = /data/ds000114/sub-01/func/sub-01_task-fingerfootlips_bold.nii.gz\n",
    "    \n",
    "Now, we can replace those paths with the accoridng {}-based strings.\n",
    "\n",
    "    anat = /data/ds000114/sub-{subject_id}/anat/sub-{subject_id}_T1w.nii.gz\n",
    "    func = /data/ds000114/sub-{subject_id}/func/sub-{subject_id}_task-{task_name}_bold.nii.gz\n",
    "\n",
    "How would this look like as a `SelectFiles` node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': 'sub-{subject_id}/anat/sub-{subject_id}_T1w.nii.gz',\n",
    "             'func': 'sub-{subject_id}/func/sub-{subject_id}_task-{task_name}_bold.nii.gz'}\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Location of the dataset folder\n",
    "sf.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "# Feed {}-based placeholder strings with values\n",
    "sf.inputs.subject_id = '01'\n",
    "sf.inputs.task_name = 'fingerfootlips'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's check if we get what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170716-02:13:43,303 workflow INFO:\n",
      "\t Executing node selectfiles in dir: /tmp/tmpzr_3jkhd/selectfiles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "anat = /data/ds000114/sub-01/anat/sub-01_T1w.nii.gz\n",
       "func = /data/ds000114/sub-01/func/sub-01_task-fingerfootlips_bold.nii.gz"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perfect! But why is `SelectFiles` more flexible than `DataGrabber`? First, you perhaps noticed that with the {}-based string, we can reuse the same input (e.g. `subject_id`) multiple time in the same string, without feeding it multiple times into the template.\n",
    "\n",
    "Additionally, you can also select multiple files without the need of an iterable node. For example, let's assume we want to select both anatomical images (`'sub-01'` and `'sub-02'`) at once. We can do this by using the following file template:\n",
    "\n",
    "    'sub-0[1,2]/anat/sub-0[1,2]_T1w.nii.gz'\n",
    "\n",
    "Let's see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170716-02:23:29,661 workflow INFO:\n",
      "\t Executing node selectfiles in dir: /tmp/tmpv6q8umoi/selectfiles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "anat = ['/data/ds000114/sub-01/anat/sub-01_T1w.nii.gz', '/data/ds000114/sub-02/anat/sub-02_T1w.nii.gz']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nipype import SelectFiles, Node\n",
    "from os.path import abspath as opap\n",
    "\n",
    "# String template with {}-based strings\n",
    "templates = {'anat': 'sub-0[1,2]/anat/sub-0[1,2]_T1w.nii.gz'}\n",
    "\n",
    "\n",
    "# Create SelectFiles node\n",
    "sf = Node(SelectFiles(templates),\n",
    "          name='selectfiles')\n",
    "\n",
    "# Location of the dataset folder\n",
    "sf.inputs.base_directory = '/data/ds000114'\n",
    "\n",
    "# Print SelectFiles output\n",
    "sf.run().outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As you can see, now `anat` contains two file paths, one for the first and one for the second subject. As a side node, you could have also gotten them same thing with the wild card `*`:\n",
    "\n",
    "    'sub-0*/anat/sub-0*_T1w.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## FreeSurferSource\n",
    "\n",
    "***Note: FreeSurfer and the recon-all output is not included in this tutorial.***\n",
    "\n",
    "`FreeSurferSource` is a specific case of a file grabber that felicitates the data import of outputs from the FreeSurfer recon-all algorithm. This of course requires that you've already run `recon-all` on your subject.\n",
    "\n",
    "Before you can run `FreeSurferSource`, you first have to specify the path to the FreeSurfer output folder, i.e. you have to specify the SUBJECTS_DIR variable. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.freesurfer import FSCommand\n",
    "from os.path import abspath as opap\n",
    "\n",
    "# Path to your freesurfer output folder\n",
    "fs_dir = opap('/data/ds000114/derivatives/freesurfer')\n",
    "\n",
    "# Set SUBJECTS_DIR\n",
    "FSCommand.set_default_subjects_dir(fs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To create the `FreeSurferSource` node, do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nipype import Node\n",
    "from nipype.interfaces.io import FreeSurferSource\n",
    "\n",
    "# Create FreeSurferSource node\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir),\n",
    "                name='fssource')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now run it for a specific subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170716-02:30:13,899 workflow INFO:\n",
      "\t Executing node fssource in dir: /tmp/tmpicgq9wsr/fssource\n",
      "170716-02:30:13,909 root ERROR:\n",
      "\t Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-34-6491b09a7842>\", line 2, in <module>\n",
      "    result = fssource.run() #TODO: doesn't work! I also cant run datalad get files that are reported to not exist\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/nipype/pipeline/engine/nodes.py\", line 372, in run\n",
      "    self._run_interface()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in _run_interface\n",
      "    old_cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.5/inspect.py\", line 701, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/opt/conda/lib/python3.5/inspect.py\", line 685, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/opt/conda/lib/python3.5/posixpath.py\", line 361, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "fssource.inputs.subject_id = 'sub-01'\n",
    "result = fssource.run() #TODO: doesn't work! I also cant run datalad get files that are reported to not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Did it work? Let's try to access multiple FreeSurfer outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aparc_aseg: <undefined>\n",
      "\n",
      "brainmask: <undefined>\n",
      "\n",
      "inflated: <undefined>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('aparc_aseg: %s\\n' % result.outputs.aparc_aseg)\n",
    "print('brainmask: %s\\n' % result.outputs.brainmask)\n",
    "print('inflated: %s\\n' % result.outputs.inflated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems to be working as it should. But as you can see, the `inflated` output actually contains the file location for both hemispheres. With `FreeSurferSource` we can also restrict the file selection to a single hemisphere. To do this, we use the `hemi` input filed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170302-17:50:13,835 workflow INFO:\n",
      "\t Executing node fssource in dir: /tmp/tmpI0UTIX/fssource\n"
     ]
    }
   ],
   "source": [
    "fssource.inputs.hemi = 'lh'\n",
    "result = fssource.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a look again at the `inflated` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/data/ds102/freesurfer/sub001/surf/lh.inflated'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.outputs.inflated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perfect!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
